{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pathlib\nimport glob\n\nimport librosa.util\nimport librosa\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom IPython import display\nimport tensorflow_datasets as tfds\nimport datetime, os\nfrom wandb.keras import WandbCallback\nimport tensorflow_addons as tfa\n\n\n# Set seed for experiment reproducibility\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:16.681182Z","iopub.execute_input":"2021-10-02T05:36:16.68157Z","iopub.status.idle":"2021-10-02T05:36:23.591645Z","shell.execute_reply.started":"2021-10-02T05:36:16.68149Z","shell.execute_reply":"2021-10-02T05:36:23.590689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\n# Insert your wandb login key to track metrics\n# wandb.login(key='Your login key')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:25.883506Z","iopub.execute_input":"2021-10-02T05:36:25.883884Z","iopub.status.idle":"2021-10-02T05:36:26.856142Z","shell.execute_reply.started":"2021-10-02T05:36:25.883827Z","shell.execute_reply":"2021-10-02T05:36:26.855357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 35 words speech command dataset","metadata":{}},{"cell_type":"code","source":"def get_train_val_test_split(root: str, val_file: str, test_file: str):\n    \"\"\"Creates train, val, and test split according to provided val and test files.\n    Args:\n        root (str): Path to base directory of the dataset.\n        val_file (str): Path to file containing list of validation data files.\n        test_file (str): Path to file containing list of test data files.\n\n    Returns:\n        train_list (list): List of paths to training data items.\n        val_list (list): List of paths to validation data items.\n        test_list (list): List of paths to test data items.\n        train_label (list): List of train labels\n        val_label (list): List of val labels\n        test_label (list): List of test labels\n\n    \"\"\"\n\n    ####################\n    # Labels\n    ####################\n\n    label_list = [label for label in sorted(os.listdir(root)) if\n                  os.path.isdir(os.path.join(root, label)) and label[0] != \"_\"]\n    label_map = {idx: label for idx, label in enumerate(label_list)}\n    label_to_idx = {v: int(k) for k, v in label_map.items()}\n\n    ###################\n    # Split\n    ###################\n\n    all_files_set = set()\n    for label in label_list:\n        all_files_set.update(set(glob.glob(os.path.join(root, label, \"*.wav\"))))\n\n    with open(val_file, \"r\") as f:\n        val_files_set = set(map(lambda a: os.path.join(root, a), f.read().rstrip(\"\\n\").split(\"\\n\")))\n\n    with open(test_file, \"r\") as f:\n        test_files_set = set(map(lambda a: os.path.join(root, a), f.read().rstrip(\"\\n\").split(\"\\n\")))\n\n    assert len(val_files_set.intersection(\n        test_files_set)) == 0, \"Sanity check: No files should be common between val and test.\"\n\n    all_files_set -= val_files_set\n    all_files_set -= test_files_set\n\n    train_list, val_list, test_list = list(all_files_set), list(val_files_set), list(test_files_set)\n\n    print(f\"Number of training samples: {len(train_list)}\")\n    print(f\"Number of validation samples: {len(val_list)}\")\n    print(f\"Number of test samples: {len(test_list)}\")\n\n    train_label = []\n    val_label = []\n    test_label = []\n\n    for path in train_list:\n        train_label.append(label_to_idx[path.split('/')[-2]])\n\n    for path in val_list:\n        val_label.append(label_to_idx[path.split('/')[-2]])\n\n    for path in test_list:\n        test_label.append(label_to_idx[path.split('/')[-2]])\n\n    return train_list, val_list, test_list, train_label, val_label, test_label","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:28.99479Z","iopub.execute_input":"2021-10-02T05:36:28.99511Z","iopub.status.idle":"2021-10-02T05:36:29.009692Z","shell.execute_reply.started":"2021-10-02T05:36:28.995079Z","shell.execute_reply":"2021-10-02T05:36:29.008763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def time_shift(wav: np.ndarray, sr: int, s_min: float, s_max: float) -> np.ndarray:\n    \"\"\"Time shift augmentation.\n    Refer to https://www.kaggle.com/haqishen/augmentation-methods-for-audio#1.-Time-shifting.\n    Changed np.r_ to np.hstack for numba support.\n    Args:\n        wav (np.ndarray): Waveform array of shape (n_samples,).\n        sr (int): Sampling rate.\n        s_min (float): Minimum fraction of a second by which to shift.\n        s_max (float): Maximum fraction of a second by which to shift.\n    \n    Returns:\n        wav_time_shift (np.ndarray): Time-shifted waveform array.\n    \"\"\"\n\n    start = int(np.random.uniform(sr * s_min, sr * s_max))\n    if start >= 0:\n        wav_time_shift = np.hstack((wav[start:], np.random.uniform(-0.001, 0.001, start)))\n    else:\n        wav_time_shift = np.hstack((np.random.uniform(-0.001, 0.001, -start), wav[:start]))\n    \n    return wav_time_shift\n\n\ndef resample(x: np.ndarray, sr: int, r_min: float, r_max: float) -> np.ndarray:\n    \"\"\"Resamples waveform.\n    Args:\n        x (np.ndarray): Input waveform, array of shape (n_samples, ).\n        sr (int): Sampling rate.\n        r_min (float): Minimum percentage of resampling.\n        r_max (float): Maximum percentage of resampling.\n    \"\"\"\n\n    sr_new = sr * np.random.uniform(r_min, r_max)\n    x = librosa.resample(x, sr, sr_new)\n    return x, sr_new\n\n\n\ndef spec_augment(mel_spec: np.ndarray, n_time_masks: int, time_mask_width: int, n_freq_masks: int, freq_mask_width: int):\n    \"\"\"Numpy implementation of spectral augmentation.\n    Args:\n        mel_spec (np.ndarray): Mel spectrogram, array of shape (n_mels, T).\n        n_time_masks (int): Number of time bands.   \n        time_mask_width (int): Max width of each time band.\n        n_freq_masks (int): Number of frequency bands.\n        freq_mask_width (int): Max width of each frequency band.\n    Returns:\n        mel_spec (np.ndarray): Spectrogram with random time bands and freq bands masked out.\n    \"\"\"\n    \n    offset, begin = 0, 0\n\n    for _ in range(n_time_masks):\n        offset = np.random.randint(0, time_mask_width)\n        begin = np.random.randint(0, mel_spec.shape[1] - offset)\n        mel_spec[:, begin: begin + offset] = 0.0\n    \n    for _ in range(n_freq_masks):\n        offset = np.random.randint(0, freq_mask_width)\n        begin = np.random.randint(0, mel_spec.shape[0] - offset)\n        mel_spec[begin: begin + offset, :] = 0.0\n\n    return mel_spec","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:30.979018Z","iopub.execute_input":"2021-10-02T05:36:30.979333Z","iopub.status.idle":"2021-10-02T05:36:30.990689Z","shell.execute_reply.started":"2021-10-02T05:36:30.979303Z","shell.execute_reply":"2021-10-02T05:36:30.989449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_generator(data_list: list, label_list: list, augment: bool):\n    \"\"\"\n    Generator function to create samples\n    :param data: Data list\n    :param label_list: Label list\n    :return:\n    \"\"\"\n\n\n    def transform(x, augment=True):\n        sr = 16000\n        x = librosa.util.fix_length(x, sr)\n        x = librosa.feature.melspectrogram(y=x, n_fft=480, win_length=480, hop_length=160, center=False)\n        x = librosa.feature.mfcc(S=librosa.power_to_db(x), n_mfcc=40)\n        if augment:\n            x = spec_augment(mel_spec=x, n_time_masks=2, time_mask_width=25, n_freq_masks=2, freq_mask_width=7)\n        x = tf.expand_dims(x, axis=-1)\n        #x = tf.tile(x, [1, 1, 3])\n        return x\n\n    for audio_file, label in zip(data_list, label_list):\n        \n        x = librosa.load(audio_file, sr=16000)[0]\n        x = transform(x, augment)\n        label = tf.convert_to_tensor(label, dtype=tf.int32)\n        label = tf.one_hot(label, depth=35)\n        yield x, label\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:32.930299Z","iopub.execute_input":"2021-10-02T05:36:32.930661Z","iopub.status.idle":"2021-10-02T05:36:32.940814Z","shell.execute_reply.started":"2021-10-02T05:36:32.93063Z","shell.execute_reply":"2021-10-02T05:36:32.939637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"markdown","source":"## Model architecture","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n\nclass Patches(tf.keras.layers.Layer):\n    \"\"\"\n    Extract patches from images\n    \"\"\"\n    def __init__(self, patch_size_w, patch_size_h):\n        super(Patches, self).__init__()\n        \n        self.w = patch_size_w\n        self.h = patch_size_h\n\n    def call(self, images):\n    \n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.w, self.h, 1],\n            strides=[1, self.w, self.h, 1],\n            rates=[1, 1, 1, 1],\n            padding='SAME',\n        )\n     \n        dim = patches.shape[-1]\n\n        patches = tf.reshape(patches, (batch_size, -1, dim))\n        return patches\n\n\nclass Mixer(tf.keras.layers.Layer):\n    def __init__(self, S, C, DS, DC):\n        \"\"\"\n        Mixer layer for the MLP mixer\n        :param S: Number of patches\n        :param C: Hidden dimension for projection\n        :param DS: tunable token mixing hidden width\n        :param DC: tunable channel mixing hidden width\n        \"\"\"\n        super(Mixer, self).__init__()\n        self.layer_norm = tf.keras.layers.LayerNormalization()\n        self.S = S\n        self.C = C\n        self.DS = DS\n        self.DC = DC\n        \n        w_init = tf.random_normal_initializer()\n\n        self.W1 = tf.Variable(initial_value=w_init(shape=(S, DS), dtype=\"float32\"),trainable=True, name='W1')\n        self.W2 = tf.Variable(initial_value=w_init(shape=(DS, S), dtype=\"float32\"),trainable=True, name='W2')\n        self.W3 = tf.Variable(initial_value=w_init(shape=(C, DC), dtype=\"float32\"),trainable=True, name='W3')\n        self.W4 = tf.Variable(initial_value=w_init(shape=(DC, C), dtype=\"float32\"),trainable=True, name='W4')\n\n    def call(self, X):\n        \"\"\"\n        Call function of mixer layer\n        :param X: Input\n        :return:\n        \"\"\"\n        X_T = tf.transpose(self.layer_norm(X), perm=(0, 2, 1))\n        \n        W1X = tf.matmul(X_T, self.W1)\n        \n        U = X + tf.transpose(tf.matmul(tf.nn.gelu(W1X), self.W2), perm=(0, 2, 1))\n\n        W3U = tf.matmul(self.layer_norm(U), self.W3)\n        Y = U + tf.matmul(tf.nn.gelu(W3U), self.W4)\n\n        return Y\n\n\nclass MLPMixer(tf.keras.models.Model):\n    def __init__(self, patch_size_w, patch_size_h,  C, DS, DC, num_of_mixer_blocks,  num_classes):\n        \"\"\"\n        Creates the Mixer model\n        :param patch_size: Patch size\n        :param S: number of patches\n        :param C: dimension of projection layer\n        :param DS: tunable token mixing hidden width\n        :param DC: tunable channel mixing hidden width\n        :param num_of_mixer_blocks: number of mixer layers\n        :param num_classes: number of classes\n        \"\"\"\n        super(MLPMixer, self).__init__()\n        self.projection = tf.keras.layers.Dense(C)\n        self.S = int((40*98)/(patch_size_w * patch_size_h))\n        self.mixer = [Mixer(self.S, C, DS, DC,) for _ in range(num_of_mixer_blocks)]\n        self.C = C\n        self.DS = DS\n        self.DC = DC\n        self.num_classes = num_classes\n        self.patch_w = patch_size_w\n        self.patch_h = patch_size_h\n\n        \n        self.classification_layer = tf.keras.models.Sequential([\n            tf.keras.layers.GlobalAveragePooling1D(),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Dense(self.num_classes, activation='softmax')\n        ])\n\n    def call(self, images):\n        \"\"\"\n        Call function for MLPMixer model\n        :param images: input image\n        :return:\n        \"\"\"\n        patcher = Patches(self.patch_w, self.patch_h)\n\n        X = patcher(images)\n        \n        X = self.projection(X)\n        \n        for block in self.mixer:\n            X = block(X)\n        \n        out = self.classification_layer(X)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:36.046634Z","iopub.execute_input":"2021-10-02T05:36:36.046966Z","iopub.status.idle":"2021-10-02T05:36:36.076599Z","shell.execute_reply.started":"2021-10-02T05:36:36.046927Z","shell.execute_reply":"2021-10-02T05:36:36.075725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Learning rate scheduler \n","metadata":{}},{"cell_type":"code","source":"class CosineScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self,\n                learning_rate_base,\n                total_steps,\n                warmup_learning_rate=0.0,\n                warmup_steps=0):\n        self.learning_rate_base = learning_rate_base\n        self.total_steps = total_steps\n        self.warmup_learning_rate =warmup_learning_rate\n        self.warmup_steps = warmup_steps\n    \n    def __call__(self,step):\n        learning_rate = 0.5 * self.learning_rate_base * (1 + tf.cos(\n            np.pi * \n            (tf.cast(step, tf.float32) - self.warmup_steps)/ float(self.total_steps-self.warmup_steps)))\n        if self.warmup_steps > 0:\n            slope = (self.learning_rate_base - self.warmup_learning_rate) / self.warmup_steps\n            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n            learning_rate = tf.where(step < self.warmup_steps, warmup_rate, learning_rate)\n        lr = tf.where(step > self.total_steps, 0.0, learning_rate, name='learning_rate')\n        wandb.log({\"lr\": lr})\n        return lr\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:37.328714Z","iopub.execute_input":"2021-10-02T05:36:37.329039Z","iopub.status.idle":"2021-10-02T05:36:37.337785Z","shell.execute_reply.started":"2021-10-02T05:36:37.329011Z","shell.execute_reply":"2021-10-02T05:36:37.336526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training function for a single epoch","metadata":{}},{"cell_type":"code","source":"# Train the model\n\ndef model_train(features, labels, model, loss_func,optimizer,train_acc,train_loss):\n    # Define the GradientTape context\n    with tf.GradientTape() as tape:\n        # Get the probabilities\n        predictions = model(features)\n        # Calculate the loss\n        loss = loss_func(labels, predictions)\n    # Get the gradients\n    gradients = tape.gradient(loss, model.trainable_variables)\n    # Update the weights\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    # Update the loss and accuracy\n    train_loss(loss)\n    train_acc(labels, predictions)\n    loss = train_loss.result()\n    wandb.log({\"train_loss\": loss.numpy()})","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:38.879316Z","iopub.execute_input":"2021-10-02T05:36:38.879663Z","iopub.status.idle":"2021-10-02T05:36:38.887929Z","shell.execute_reply.started":"2021-10-02T05:36:38.879632Z","shell.execute_reply":"2021-10-02T05:36:38.887005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model validation function for a single epoch","metadata":{}},{"cell_type":"code","source":"\ndef model_validate(features, labels,model,loss_func,valid_loss,val_acc):\n    predictions = model(features)\n    v_loss = loss_func(labels, predictions)\n\n    valid_loss(v_loss)\n    val_acc(labels, predictions)\n    (val_loss, val_acc) = valid_loss.result(), val_acc.result()\n    wandb.log({\n               \"val_loss\": val_loss.numpy()\n    })","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:36:40.857335Z","iopub.execute_input":"2021-10-02T05:36:40.857729Z","iopub.status.idle":"2021-10-02T05:36:40.863514Z","shell.execute_reply.started":"2021-10-02T05:36:40.857696Z","shell.execute_reply":"2021-10-02T05:36:40.86211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training function","metadata":{}},{"cell_type":"code","source":"def train(train_dataset,\n          val_dataset,\n          model,\n          optimizer,\n          loss_func,\n          train_loss,\n          train_acc,\n          valid_loss,\n          valid_acc,\n          epochs\n         ):\n    max_val_acc = 0\n    checkpoint_path = \"training_1/cp.ckpt\"\n\n    for epoch in range(epochs):\n        # Run the model through train and test sets respectively\n        for (features, labels) in train_dataset:\n            model_train(features, labels, model, loss_func,optimizer,train_acc,train_loss)\n\n        for val_features, val_labels in val_dataset:\n            model_validate(val_features, val_labels,model,loss_func,valid_loss,valid_acc)\n\n        # Grab the results\n        (loss, acc) = train_loss.result(), train_acc.result()\n        (val_loss, val_acc) = valid_loss.result(), valid_acc.result()\n        if val_acc > max_val_acc:\n            max_val_acc= val_acc\n            model.save_weights(checkpoint_path)\n\n        # Clear the current state of the metrics\n        train_loss.reset_states(), train_acc.reset_states()\n        valid_loss.reset_states(), valid_acc.reset_states()\n\n        # Local logging\n        template = \"Epoch {}, loss: {:.3f}, acc: {:.3f}, val_loss: {:.3f}, val_acc: {:.3f}\"\n        print (template.format(epoch+1,\n                             loss,\n                             acc,\n                             val_loss,\n                             val_acc))\n        wandb.log({\"train_accuracy\": acc,\n                  \"val_accuracy\": val_acc})\n    wandb.log({\"best_val_acc\": max_val_acc})\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:37:11.533988Z","iopub.execute_input":"2021-10-02T05:37:11.534319Z","iopub.status.idle":"2021-10-02T05:37:11.542669Z","shell.execute_reply.started":"2021-10-02T05:37:11.534288Z","shell.execute_reply":"2021-10-02T05:37:11.541689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initiate training","metadata":{}},{"cell_type":"code","source":"\nconfig_defaults= {\n    \"C\": 256,\n    \"DS\" :128,\n    \"DC\" : 1024,\n    \"num_of_mixer_blocks\" : 8,\n    'learning_rate' : 0.0003\n}\nwandb.init(config=config_defaults,project=\"MLP-mixer-audio\")\ntrain_list, val_list, test_list, train_label, val_label, test_label =  get_train_val_test_split('../input/google-speech-v2', \n                                                                                            '../input/google-speech-v2/validation_list.txt', \n                                                                                            '../input/google-speech-v2/testing_list.txt')\ntrain_dataset = tf.data.Dataset.from_generator(\n        sample_generator,\n        args=(train_list, train_label,True),\n        output_types=(tf.float32, tf.float32),\n        output_shapes=((40, 98, 1), (35,))\n    )\nval_dataset = tf.data.Dataset.from_generator(\n        sample_generator,\n        args=(val_list, val_label,False),\n        output_types=(tf.float32, tf.float32),\n        output_shapes=((40, 98, 1), (35,))\n    )\ntest_dataset = tf.data.Dataset.from_generator(\n        sample_generator,\n        args=(test_list, test_label,False),\n        output_types=(tf.float32, tf.float32),\n        output_shapes=((40, 98, 1), (35,))\n    )\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.shuffle(1024).batch(64).cache()\nval_dataset = val_dataset.shuffle(1024).batch(64).cache()\n\n\nmodel = MLPMixer(40, 1, C=wandb.config.C, DS=wandb.config.DS, DC=wandb.config.DC, num_of_mixer_blocks=wandb.config.num_of_mixer_blocks, num_classes=35)\nlearning_rate = CosineScheduler(learning_rate_base=wandb.config.learning_rate, \n                            total_steps=23000, \n                            warmup_learning_rate=0.0, \n                            warmup_steps=1660)\nloss_func = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n# Average the loss across the batch size within an epoch\ntrain_loss = tf.keras.metrics.Mean(name=\"train_loss\")\nvalid_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n\n# Specify the performance metric\ntrain_acc = tf.keras.metrics.CategoricalAccuracy(name=\"train_acc\")\nvalid_acc = tf.keras.metrics.CategoricalAccuracy(name=\"valid_acc\")\n\ntrain(train_dataset,\n     val_dataset,\n      model,\n      optimizer,\n      loss_func,\n      train_loss,\n      train_acc,\n      valid_loss,\n      valid_acc,\n     epochs = 50)\ntest_audio = []\ntest_labels = []\n\nfor audio, label in test_dataset:\n    test_audio.append(audio.numpy())\n    test_labels.append(label.numpy())\n\ntest_audio = np.array(test_audio)\ntest_labels = np.array(test_labels)\n\ny_pred = np.argmax(model.predict(test_audio), axis=1)\ny_true = np.argmax(test_labels,axis=1)\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')\nwandb.log({'test_acc': test_acc})\n\ntf.keras.backend.clear_session()\ncheckpoint_path = \"training_1/cp.ckpt\"\nnew_model = MLPMixer(40, 1, C=wandb.config.C, DS=wandb.config.DS, DC=wandb.config.DC, num_of_mixer_blocks=wandb.config.num_of_mixer_blocks, num_classes=35)\nnew_model.load_weights(checkpoint_path)\n\ny_pred = np.argmax(new_model.predict(test_audio), axis=1)\ny_true = np.argmax(test_labels,axis=1)\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')\nwandb.log({'best_test_acc': test_acc})","metadata":{"execution":{"iopub.status.busy":"2021-10-02T05:37:26.396372Z","iopub.execute_input":"2021-10-02T05:37:26.396744Z","iopub.status.idle":"2021-10-02T06:03:21.692714Z","shell.execute_reply.started":"2021-10-02T05:37:26.396716Z","shell.execute_reply":"2021-10-02T06:03:21.691696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-18T15:12:11.538279Z","iopub.execute_input":"2021-09-18T15:12:11.538656Z","iopub.status.idle":"2021-09-18T16:39:05.242572Z","shell.execute_reply.started":"2021-09-18T15:12:11.538619Z","shell.execute_reply":"2021-09-18T16:39:05.241276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}